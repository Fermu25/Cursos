{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLIB1vrRew0M9dUfnUrrlM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fermu25/Cursos/blob/main/Data_sets_filtrado_datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FosbJk4L-fHV",
        "outputId": "5100973a-a40f-41db-99f0-71cd94276c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listo. Se escribió el CSV limpio en: /content/salida1.csv\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "INPUT_PATH  = \"serial_log_parte1.csv\"\n",
        "OUTPUT_PATH = \"salida1.csv\"\n",
        "\n",
        "\n",
        "TS_RE = re.compile(r'^(?P<ts>\\d{2}:\\d{2}:\\d{2}\\.\\d{3})\\s*->\\s*(?P<rest>.*)$')\n",
        "\n",
        "PRESS_RE = re.compile(\n",
        "    r'Presiones:\\s*P1\\s*=\\s*([-\\d\\.NaNnan]+)\\s*mmHg\\s*\\|\\s*P2\\s*=\\s*([-\\d\\.NaNnan]+)\\s*mmHg',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "IR_RE = re.compile(\n",
        "    r'IR\\s*Canal\\s*(\\d+):\\s*Obj\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C,\\s*Amb\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "DS_RE = re.compile(\n",
        "    r'DS18B20:\\s*T1\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C\\s*\\|\\s*T2\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C\\s*\\|\\s*T3\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C\\s*\\|\\s*T4\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "SEP_RE = re.compile(r'^-+\\s*$')\n",
        "\n",
        "def to_float(x: str):\n",
        "    x = x.strip()\n",
        "    if x.lower() == 'nan' or x == '':\n",
        "        return float('nan')\n",
        "    try:\n",
        "        return float(x)\n",
        "    except ValueError:\n",
        "        return float('nan')\n",
        "\n",
        "def parse_file(text_lines):\n",
        "    \"\"\"\n",
        "    Devuelve una lista de dicts, 1 por bloque.\n",
        "    Cada bloque comienza (normalmente) con la línea 'Presiones:' para anclar el timestamp.\n",
        "    \"\"\"\n",
        "    blocks = []\n",
        "    cur = None\n",
        "\n",
        "    def finalize_current():\n",
        "        nonlocal cur\n",
        "        if cur is not None:\n",
        "            blocks.append(cur)\n",
        "            cur = None\n",
        "\n",
        "    for raw in text_lines:\n",
        "        line = raw.strip('\\n')\n",
        "        if not line.strip():\n",
        "            continue\n",
        "\n",
        "        m = TS_RE.match(line)\n",
        "        if not m:\n",
        "            if SEP_RE.match(line):\n",
        "                finalize_current()\n",
        "            continue\n",
        "\n",
        "        ts = m.group('ts')\n",
        "        rest = m.group('rest')\n",
        "\n",
        "\n",
        "        if SEP_RE.match(rest):\n",
        "            finalize_current()\n",
        "            continue\n",
        "\n",
        "\n",
        "        mp = PRESS_RE.search(rest)\n",
        "        if mp:\n",
        "\n",
        "            finalize_current()\n",
        "            cur = {\n",
        "                'time': ts,\n",
        "                'P1_mmHg': to_float(mp.group(1)),\n",
        "                'P2_mmHg': to_float(mp.group(2)),\n",
        "                'IR2_Obj_C': float('nan'),\n",
        "                'IR2_Amb_C': float('nan'),\n",
        "                'IR3_Obj_C': float('nan'),\n",
        "                'IR3_Amb_C': float('nan'),\n",
        "                'DS_T1_C': float('nan'),\n",
        "                'DS_T2_C': float('nan'),\n",
        "                'DS_T3_C': float('nan'),\n",
        "                'DS_T4_C': float('nan'),\n",
        "            }\n",
        "            continue\n",
        "\n",
        "\n",
        "        if cur is None:\n",
        "            continue\n",
        "\n",
        "\n",
        "        mi = IR_RE.search(rest)\n",
        "        if mi:\n",
        "            canal = mi.group(1)\n",
        "            obj = to_float(mi.group(2))\n",
        "            amb = to_float(mi.group(3))\n",
        "            if canal == '2':\n",
        "                cur['IR2_Obj_C'] = obj\n",
        "                cur['IR2_Amb_C'] = amb\n",
        "            elif canal == '3':\n",
        "                cur['IR3_Obj_C'] = obj\n",
        "                cur['IR3_Amb_C'] = amb\n",
        "\n",
        "            continue\n",
        "\n",
        "\n",
        "        md = DS_RE.search(rest)\n",
        "        if md:\n",
        "            cur['DS_T1_C'] = to_float(md.group(1))\n",
        "            cur['DS_T2_C'] = to_float(md.group(2))\n",
        "            cur['DS_T3_C'] = to_float(md.group(3))\n",
        "            cur['DS_T4_C'] = to_float(md.group(4))\n",
        "            continue\n",
        "\n",
        "\n",
        "    finalize_current()\n",
        "    return blocks\n",
        "\n",
        "def compute_times(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "\n",
        "    t0 = None\n",
        "    elapsed = []\n",
        "    for t in df['time']:\n",
        "\n",
        "        h, mi, rest = t.split(':')\n",
        "        s = float(rest)\n",
        "        total = int(h)*3600 + int(mi)*60 + s\n",
        "        if t0 is None:\n",
        "            t0 = total\n",
        "        elapsed.append(total - t0)\n",
        "    df['elapsed_s'] = elapsed\n",
        "    df['dt_s'] = df['elapsed_s'].diff().fillna(0.0)\n",
        "    return df\n",
        "\n",
        "def main(in_path=INPUT_PATH, out_path=OUTPUT_PATH):\n",
        "\n",
        "    p = Path(in_path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"No se encontró el archivo de entrada: {p.resolve()}\")\n",
        "    with p.open('r', encoding='utf-8', errors='ignore') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    blocks = parse_file(lines)\n",
        "    if not blocks:\n",
        "        raise RuntimeError(\"No se pudieron extraer bloques. ¿El formato coincide con los ejemplos?\")\n",
        "\n",
        "    df = pd.DataFrame(blocks, columns=[\n",
        "        'time','P1_mmHg','P2_mmHg',\n",
        "        'IR2_Obj_C','IR2_Amb_C','IR3_Obj_C','IR3_Amb_C',\n",
        "        'DS_T1_C','DS_T2_C','DS_T3_C','DS_T4_C'\n",
        "    ])\n",
        "    df = compute_times(df)\n",
        "\n",
        "\n",
        "    cols = [\n",
        "        'time','elapsed_s','dt_s',\n",
        "        'P1_mmHg','P2_mmHg',\n",
        "        'IR2_Obj_C','IR2_Amb_C','IR3_Obj_C','IR3_Amb_C',\n",
        "        'DS_T1_C','DS_T2_C','DS_T3_C','DS_T4_C'\n",
        "    ]\n",
        "    df = df[cols]\n",
        "\n",
        "    df.to_csv(out_path, index=False, encoding='utf-8')\n",
        "    print(f\"Listo. Se escribió el CSV limpio en: {Path(out_path).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "INPUT_PATH  = \"serial_log_parte2.csv\"\n",
        "OUTPUT_PATH = \"salida2.csv\"\n",
        "\n",
        "PRESS_RE = re.compile(\n",
        "    r'Presiones:\\s*P1\\s*=\\s*([-\\d\\.NaNnan]+)\\s*mmHg\\s*\\|\\s*P2\\s*=\\s*([-\\d\\.NaNnan]+)\\s*mmHg',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "IR_RE = re.compile(\n",
        "    r'IR\\s*Canal\\s*(\\d+):\\s*Obj\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C,\\s*Amb\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "DS_RE = re.compile(\n",
        "    r'DS18B20:\\s*T1\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C\\s*\\|\\s*T2\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C\\s*\\|\\s*T3\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C\\s*\\|\\s*T4\\s*=\\s*([-\\d\\.NaNnan]+)\\s*°C',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "SEP_RE = re.compile(r'^-+\\s*$')\n",
        "\n",
        "def to_float(x: str):\n",
        "    x = (x or \"\").strip()\n",
        "    if x.lower() == \"nan\" or x == \"\":\n",
        "        return np.nan\n",
        "    try:\n",
        "        return float(x)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "def iso_to_hms_ms(iso_str: str) -> tuple[str, float]:\n",
        "    dt = datetime.fromisoformat(iso_str.replace(\"Z\",\"\"))\n",
        "    hms = dt.strftime(\"%H:%M:%S.\") + f\"{int(dt.microsecond/1000):03d}\"\n",
        "    return hms, dt.timestamp()\n",
        "\n",
        "def parse_blocks(df_raw: pd.DataFrame) -> list[dict]:\n",
        "    blocks = []\n",
        "    cur = None\n",
        "    t_anchor_epoch = None\n",
        "    for _, row in df_raw.iterrows():\n",
        "        msg = str(row['mensaje']).strip()\n",
        "        iso = str(row['iso_ts']).strip()\n",
        "        if SEP_RE.match(msg):\n",
        "            if cur is not None:\n",
        "                blocks.append(cur)\n",
        "                cur = None\n",
        "                t_anchor_epoch = None\n",
        "            continue\n",
        "        mp = PRESS_RE.search(msg)\n",
        "        if mp:\n",
        "            if cur is not None:\n",
        "                blocks.append(cur)\n",
        "            time_hms, t_epoch = iso_to_hms_ms(iso)\n",
        "            t_anchor_epoch = t_epoch\n",
        "            cur = {\n",
        "                'time': time_hms,\n",
        "                'epoch': t_anchor_epoch,\n",
        "                'P1_mmHg': to_float(mp.group(1)),\n",
        "                'P2_mmHg': to_float(mp.group(2)),\n",
        "                'IR2_Obj_C': np.nan, 'IR2_Amb_C': np.nan,\n",
        "                'IR3_Obj_C': np.nan, 'IR3_Amb_C': np.nan,\n",
        "                'DS_T1_C': np.nan, 'DS_T2_C': np.nan, 'DS_T3_C': np.nan, 'DS_T4_C': np.nan,\n",
        "            }\n",
        "            continue\n",
        "        if cur is None:\n",
        "            continue\n",
        "        mi = IR_RE.search(msg)\n",
        "        if mi:\n",
        "            canal = mi.group(1)\n",
        "            obj = to_float(mi.group(2))\n",
        "            amb = to_float(mi.group(3))\n",
        "            if canal == '2':\n",
        "                cur['IR2_Obj_C'] = obj\n",
        "                cur['IR2_Amb_C'] = amb\n",
        "            elif canal == '3':\n",
        "                cur['IR3_Obj_C'] = obj\n",
        "                cur['IR3_Amb_C'] = amb\n",
        "            continue\n",
        "        md = DS_RE.search(msg)\n",
        "        if md:\n",
        "            cur['DS_T1_C'] = to_float(md.group(1))\n",
        "            cur['DS_T2_C'] = to_float(md.group(2))\n",
        "            cur['DS_T3_C'] = to_float(md.group(3))\n",
        "            cur['DS_T4_C'] = to_float(md.group(4))\n",
        "            continue\n",
        "    if cur is not None:\n",
        "        blocks.append(cur)\n",
        "    return blocks\n",
        "\n",
        "def compute_time_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.sort_values('epoch').reset_index(drop=True)\n",
        "    t0 = df.loc[0, 'epoch']\n",
        "    df['elapsed_s'] = df['epoch'] - t0\n",
        "    df['dt_s'] = df['elapsed_s'].diff().fillna(0.0)\n",
        "    return df.drop(columns=['epoch'])\n",
        "\n",
        "def main(in_path=INPUT_PATH, out_path=OUTPUT_PATH):\n",
        "    p = Path(in_path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"No se encontró el archivo: {p.resolve()}\")\n",
        "    df_raw = pd.read_csv(\n",
        "        p,\n",
        "        header=None,\n",
        "        names=['seq', 'iso_ts', 'mensaje'],\n",
        "        dtype={'seq': 'Int64', 'iso_ts': str, 'mensaje': str},\n",
        "        keep_default_na=False,\n",
        "        encoding='utf-8',\n",
        "        delimiter=','\n",
        "    )\n",
        "    blocks = parse_blocks(df_raw)\n",
        "    if not blocks:\n",
        "        raise RuntimeError(\"No se detectaron bloques (líneas con 'Presiones'). Revisa el formato.\")\n",
        "    df = pd.DataFrame(blocks)\n",
        "    df = compute_time_cols(df)\n",
        "    cols = [\n",
        "        'time','elapsed_s','dt_s',\n",
        "        'P1_mmHg','P2_mmHg',\n",
        "        'IR2_Obj_C','IR2_Amb_C','IR3_Obj_C','IR3_Amb_C',\n",
        "        'DS_T1_C','DS_T2_C','DS_T3_C','DS_T4_C'\n",
        "    ]\n",
        "    for c in cols:\n",
        "        if c not in df.columns:\n",
        "            df[c] = np.nan\n",
        "    df = df[cols]\n",
        "    df.to_csv(out_path, index=False, encoding='utf-8')\n",
        "    print(f\"CSV homogéneo escrito en: {Path(out_path).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNvX2fwn_ZEq",
        "outputId": "77c9ce76-6e1e-4515-cf05-1645d8d2f63c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV homogéneo escrito en: /content/salida2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "CSV1 = \"salida1.csv\"\n",
        "CSV2 = \"salida2.csv\"\n",
        "OUTPUT = \"salida_unida.csv\"\n",
        "\n",
        "def unir_csvs(csv1, csv2, out_path=OUTPUT):\n",
        "    df1 = pd.read_csv(csv1)\n",
        "    df2 = pd.read_csv(csv2)\n",
        "    df = pd.concat([df1, df2], ignore_index=True)\n",
        "    df['elapsed_s'] = pd.to_numeric(df['elapsed_s'], errors='coerce')\n",
        "    df['dt_s'] = pd.to_numeric(df['dt_s'], errors='coerce')\n",
        "    df = df.sort_values('elapsed_s').reset_index(drop=True)\n",
        "    df['elapsed_s'] = df.index.to_numpy(dtype=float)\n",
        "    df['dt_s'] = df['elapsed_s'].diff().fillna(0.0)\n",
        "    cols = [\n",
        "        'time','elapsed_s','dt_s',\n",
        "        'P1_mmHg','P2_mmHg',\n",
        "        'IR2_Obj_C','IR2_Amb_C','IR3_Obj_C','IR3_Amb_C',\n",
        "        'DS_T1_C','DS_T2_C','DS_T3_C','DS_T4_C'\n",
        "    ]\n",
        "    for c in cols:\n",
        "        if c not in df.columns:\n",
        "            df[c] = np.nan\n",
        "    df = df[cols]\n",
        "    df.to_csv(out_path, index=False, encoding='utf-8')\n",
        "    print(f\"Archivo combinado guardado en: {Path(out_path).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unir_csvs(CSV1, CSV2, OUTPUT)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PszebkBJ_mWL",
        "outputId": "c79c04b7-2e9f-4122-ca25-47197dd119ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo combinado guardado en: /content/salida_unida.csv\n"
          ]
        }
      ]
    }
  ]
}